{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.4 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.4"
    },
    "interpreter": {
      "hash": "25bf1dab56f13e21d80318cd5e789e076f92a14fa9924f370a2a818164c863f4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l46BNK3rAfJw"
      },
      "source": [
        "https://towardsdatascience.com/stock-prediction-using-recurrent-neural-networks-c03637437578\n",
        "\n",
        "https://viblo.asia/p/recurrent-neural-networkphan-1-tong-quan-va-ung-dung-jvElaB4m5kw\n",
        "\n",
        "https://nttuan8.com/bai-13-recurrent-neural-network/\n",
        "\n",
        "https://lilianweng.github.io/lil-log/2017/07/08/predict-stock-prices-using-RNN-part-1.html\n",
        "\n",
        "https://www.kaggle.com/raoulma/ny-stock-price-prediction-rnn-lstm-gru"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ODC2IfVJGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffc2218-bd35-4c3f-efb2-7b333eb6fe27"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "\n",
        "# split data in 80%/10%/10% train/validation/test sets\n",
        "valid_set_size_percentage = 10 \n",
        "test_set_size_percentage = 10 \n",
        "\n",
        "# #display parent directory and working directory\n",
        "# print(os.path.dirname(os.getcwd())+':', os.listdir(os.path.dirname(os.getcwd())));\n",
        "# print(os.getcwd()+':', os.listdir(os.getcwd()));"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLF5ez9BVM7v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "03fe2f08-616a-4c3c-f4aa-e11b85f2da9d"
      },
      "source": [
        "# import all stock prices \n",
        "df = pd.read_csv(\"../db/IBM.csv\", index_col = 0)\n",
        "df.info()\n",
        "df\n",
        "\n",
        "# # number of different stocks\n",
        "# print('\\nnumber of different stocks: ', len(list(set(df.symbol))))\n",
        "# print(list(set(df.symbol))[:10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\nIndex: 2705 entries, 2010-10-11 to 2021-07-09\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Open       2705 non-null   float64\n 1   High       2705 non-null   float64\n 2   Low        2705 non-null   float64\n 3   Close      2705 non-null   float64\n 4   Adj Close  2705 non-null   float64\n 5   Volume     2705 non-null   int64  \ndtypes: float64(5), int64(1)\nmemory usage: 147.9+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Open        High         Low       Close   Adj Close  \\\n",
              "Date                                                                     \n",
              "2010-10-11  138.789993  139.940002  138.639999  139.660004   97.898521   \n",
              "2010-10-12  138.399994  139.990005  138.270004  139.850006   98.031708   \n",
              "2010-10-13  139.910004  141.479996  139.779999  140.369995   98.396217   \n",
              "2010-10-14  140.350006  141.500000  139.690002  141.500000   99.188316   \n",
              "2010-10-15  142.100006  142.100006  140.539993  141.059998   98.879852   \n",
              "...                ...         ...         ...         ...         ...   \n",
              "2021-07-02  146.910004  146.949997  139.460007  140.020004  140.020004   \n",
              "2021-07-06  139.990005  140.419998  137.100006  138.779999  138.779999   \n",
              "2021-07-07  138.759995  140.330002  138.759995  139.820007  139.820007   \n",
              "2021-07-08  137.779999  141.309998  137.660004  140.740005  140.740005   \n",
              "2021-07-09  141.449997  141.979996  140.839996  141.520004  141.520004   \n",
              "\n",
              "              Volume  \n",
              "Date                  \n",
              "2010-10-11   4004300  \n",
              "2010-10-12   5637300  \n",
              "2010-10-13   8784300  \n",
              "2010-10-14   5653100  \n",
              "2010-10-15   7220400  \n",
              "...              ...  \n",
              "2021-07-02  16811200  \n",
              "2021-07-06   8093700  \n",
              "2021-07-07   4059700  \n",
              "2021-07-08   5487400  \n",
              "2021-07-09   3903500  \n",
              "\n",
              "[2705 rows x 6 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2010-10-11</th>\n      <td>138.789993</td>\n      <td>139.940002</td>\n      <td>138.639999</td>\n      <td>139.660004</td>\n      <td>97.898521</td>\n      <td>4004300</td>\n    </tr>\n    <tr>\n      <th>2010-10-12</th>\n      <td>138.399994</td>\n      <td>139.990005</td>\n      <td>138.270004</td>\n      <td>139.850006</td>\n      <td>98.031708</td>\n      <td>5637300</td>\n    </tr>\n    <tr>\n      <th>2010-10-13</th>\n      <td>139.910004</td>\n      <td>141.479996</td>\n      <td>139.779999</td>\n      <td>140.369995</td>\n      <td>98.396217</td>\n      <td>8784300</td>\n    </tr>\n    <tr>\n      <th>2010-10-14</th>\n      <td>140.350006</td>\n      <td>141.500000</td>\n      <td>139.690002</td>\n      <td>141.500000</td>\n      <td>99.188316</td>\n      <td>5653100</td>\n    </tr>\n    <tr>\n      <th>2010-10-15</th>\n      <td>142.100006</td>\n      <td>142.100006</td>\n      <td>140.539993</td>\n      <td>141.059998</td>\n      <td>98.879852</td>\n      <td>7220400</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-07-02</th>\n      <td>146.910004</td>\n      <td>146.949997</td>\n      <td>139.460007</td>\n      <td>140.020004</td>\n      <td>140.020004</td>\n      <td>16811200</td>\n    </tr>\n    <tr>\n      <th>2021-07-06</th>\n      <td>139.990005</td>\n      <td>140.419998</td>\n      <td>137.100006</td>\n      <td>138.779999</td>\n      <td>138.779999</td>\n      <td>8093700</td>\n    </tr>\n    <tr>\n      <th>2021-07-07</th>\n      <td>138.759995</td>\n      <td>140.330002</td>\n      <td>138.759995</td>\n      <td>139.820007</td>\n      <td>139.820007</td>\n      <td>4059700</td>\n    </tr>\n    <tr>\n      <th>2021-07-08</th>\n      <td>137.779999</td>\n      <td>141.309998</td>\n      <td>137.660004</td>\n      <td>140.740005</td>\n      <td>140.740005</td>\n      <td>5487400</td>\n    </tr>\n    <tr>\n      <th>2021-07-09</th>\n      <td>141.449997</td>\n      <td>141.979996</td>\n      <td>140.839996</td>\n      <td>141.520004</td>\n      <td>141.520004</td>\n      <td>3903500</td>\n    </tr>\n  </tbody>\n</table>\n<p>2705 rows Ã— 6 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNsT8mRIVe7e"
      },
      "source": [
        "df.describe()\n",
        "# df.columns=[\"open\", \"high\",\"low\", \"close\", \"adjclose\", \"volume\"]\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Open         High          Low        Close    Adj Close  \\\n",
              "count  2705.000000  2705.000000  2705.000000  2705.000000  2705.000000   \n",
              "mean    159.543061   160.735464   158.404961   159.582895   127.801056   \n",
              "std      25.341834    25.357783    25.374706    25.370052    12.702604   \n",
              "min      94.599998    97.739998    90.559998    94.769997    88.795891   \n",
              "25%     141.119995   142.229996   140.169998   141.220001   119.876671   \n",
              "50%     155.960007   157.199997   154.729996   155.830002   127.041580   \n",
              "75%     182.199997   183.429993   180.990005   182.229996   137.951584   \n",
              "max     215.380005   215.899994   214.300003   215.800003   157.775299   \n",
              "\n",
              "             Volume  \n",
              "count  2.705000e+03  \n",
              "mean   4.677263e+06  \n",
              "std    2.589162e+06  \n",
              "min    1.193000e+06  \n",
              "25%    3.241100e+06  \n",
              "50%    4.023100e+06  \n",
              "75%    5.210300e+06  \n",
              "max    3.806350e+07  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2705.000000</td>\n      <td>2705.000000</td>\n      <td>2705.000000</td>\n      <td>2705.000000</td>\n      <td>2705.000000</td>\n      <td>2.705000e+03</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>159.543061</td>\n      <td>160.735464</td>\n      <td>158.404961</td>\n      <td>159.582895</td>\n      <td>127.801056</td>\n      <td>4.677263e+06</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>25.341834</td>\n      <td>25.357783</td>\n      <td>25.374706</td>\n      <td>25.370052</td>\n      <td>12.702604</td>\n      <td>2.589162e+06</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>94.599998</td>\n      <td>97.739998</td>\n      <td>90.559998</td>\n      <td>94.769997</td>\n      <td>88.795891</td>\n      <td>1.193000e+06</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>141.119995</td>\n      <td>142.229996</td>\n      <td>140.169998</td>\n      <td>141.220001</td>\n      <td>119.876671</td>\n      <td>3.241100e+06</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>155.960007</td>\n      <td>157.199997</td>\n      <td>154.729996</td>\n      <td>155.830002</td>\n      <td>127.041580</td>\n      <td>4.023100e+06</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>182.199997</td>\n      <td>183.429993</td>\n      <td>180.990005</td>\n      <td>182.229996</td>\n      <td>137.951584</td>\n      <td>5.210300e+06</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>215.380005</td>\n      <td>215.899994</td>\n      <td>214.300003</td>\n      <td>215.800003</td>\n      <td>157.775299</td>\n      <td>3.806350e+07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWZibWSZVlvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380ef01f-42a2-4d8e-96ef-4509e84f05da",
        "tags": []
      },
      "source": [
        "# choose a specific stock\n",
        "# drop feature: volume\n",
        "# normalize stock data\n",
        "# create train, validation and test data sets\n",
        "\n",
        "# function to create train, validation, test data given stock data and sequence length\n",
        "def load_data(stock, seq_len):\n",
        "    data_raw = stock\n",
        "    data = []\n",
        "    \n",
        "    # create all possible sequences of length seq_len\n",
        "    for index in range(len(data_raw) - seq_len): \n",
        "        data.append(data_raw[index: index + seq_len])\n",
        "\n",
        "    data = np.array(data)\n",
        "\n",
        "    valid_set_size = int(np.round(valid_set_size_percentage/100*data.shape[0]));  \n",
        "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]));\n",
        "    train_set_size = data.shape[0] - (valid_set_size + test_set_size);\n",
        "    \n",
        "    x_train = data[:train_set_size,:-1,:4]\n",
        "    y_train = data[:train_set_size,-1,:4]\n",
        "    \n",
        "    x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,:4]\n",
        "    y_valid = data[train_set_size:train_set_size+valid_set_size,-1,:4]\n",
        "    \n",
        "    x_test = data[train_set_size+valid_set_size:,:-1,:4]\n",
        "    y_test = data[train_set_size+valid_set_size:,-1,:4]\n",
        "    \n",
        "    return [x_train, y_train, x_valid, y_valid, x_test, y_test]\n",
        "\n",
        "# choose one stock\n",
        "df_stock = df.copy()\n",
        "df_stock = df_stock[['Open', 'High', 'Low', 'Close']]\n",
        "\n",
        "cols = list(df_stock.columns.values)\n",
        "print('df_stock.columns.values = ', cols)\n",
        "\n",
        "# min-max normalization of stock\n",
        "scaler = MinMaxScaler()\n",
        "df_stock_norm = df_stock.copy()\n",
        "df_stock_norm = df_stock_norm.values\n",
        "df_stock_norm = scaler.fit_transform(df_stock_norm)\n",
        "\n",
        "# create train, test data\n",
        "seq_len = 20 # choose sequence length\n",
        "x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(df_stock_norm, seq_len)\n",
        "print('x_train.shape = ',x_train.shape)\n",
        "print('y_train.shape = ', y_train.shape)\n",
        "print('x_valid.shape = ',x_valid.shape)\n",
        "print('y_valid.shape = ', y_valid.shape)\n",
        "print('x_test.shape = ', x_test.shape)\n",
        "print('y_test.shape = ',y_test.shape)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_stock.columns.values =  ['Open', 'High', 'Low', 'Close']\nx_train.shape =  (2149, 19, 4)\ny_train.shape =  (2149, 4)\nx_valid.shape =  (268, 19, 4)\ny_valid.shape =  (268, 4)\nx_test.shape =  (268, 19, 4)\ny_test.shape =  (268, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaAsGvONXZG7"
      },
      "source": [
        "# 4. Model and validate data \n",
        "# RNNs with basic\n",
        "\n",
        "## Basic Cell RNN in tensorflow\n",
        "\n",
        "index_in_epoch = 0;\n",
        "perm_array  = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(perm_array)\n",
        "\n",
        "# function to get the next batch\n",
        "def get_next_batch(batch_size):\n",
        "    global index_in_epoch, x_train, perm_array   \n",
        "    start = index_in_epoch\n",
        "    index_in_epoch += batch_size\n",
        "    \n",
        "    if index_in_epoch > x_train.shape[0]:\n",
        "        np.random.shuffle(perm_array) # shuffle permutation array\n",
        "        start = 0 # start next epoch\n",
        "        index_in_epoch = batch_size\n",
        "        \n",
        "    end = index_in_epoch\n",
        "    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]\n",
        "\n",
        "# parameters\n",
        "n_steps = seq_len-1 \n",
        "n_inputs = 4 \n",
        "n_neurons = 200 \n",
        "n_outputs = 4\n",
        "n_layers = 2\n",
        "learning_rate = 0.001\n",
        "batch_size = 50\n",
        "n_epochs = 100 \n",
        "train_set_size = x_train.shape[0]\n",
        "test_set_size = x_test.shape[0]\n",
        "tf.compat.v1.reset_default_graph()\n",
        "# tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, n_outputs])\n",
        "\n",
        "# use Basic RNN Cell\n",
        "layers = [tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.elu)\n",
        "          for layer in range(n_layers)]\n",
        "\n",
        "# use Basic LSTM Cell \n",
        "#layers = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons, activation=tf.nn.elu)\n",
        "#          for layer in range(n_layers)]\n",
        "\n",
        "# use LSTM Cell with peephole connections\n",
        "#layers = [tf.contrib.rnn.LSTMCell(num_units=n_neurons, \n",
        "#                                  activation=tf.nn.leaky_relu, use_peepholes = True)\n",
        "#          for layer in range(n_layers)]\n",
        "\n",
        "# use GRU cell\n",
        "#layers = [tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=tf.nn.leaky_relu)\n",
        "#          for layer in range(n_layers)]\n",
        "                                                                     \n",
        "multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
        "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
        "\n",
        "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) \n",
        "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
        "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
        "outputs = outputs[:,n_steps-1,:] # keep only last output of sequence\n",
        "                                              \n",
        "loss = tf.reduce_mean(tf.square(outputs - y)) # loss function = mean squared error \n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
        "training_op = optimizer.minimize(loss)\n",
        "                                              \n",
        "# run graph\n",
        "with tf.Session() as sess: \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for iteration in range(int(n_epochs*train_set_size/batch_size)):\n",
        "        x_batch, y_batch = get_next_batch(batch_size) # fetch the next training batch \n",
        "        \n",
        "        # sess.run(training_op, feed_dict={X: x_batch.reshape(((50 , 19, 4))), y: y_batch.reshape(((, 4)))}) \n",
        "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch}) \n",
        "\n",
        "        if iteration % int(5*train_set_size/batch_size) == 0:\n",
        "            mse_train = loss.eval(feed_dict={X: x_train, y: y_train}) \n",
        "            mse_valid = loss.eval(feed_dict={X: x_valid, y: y_valid}) \n",
        "            print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(\n",
        "                iteration*batch_size/train_set_size, mse_train, mse_valid))\n",
        "\n",
        "    y_train_pred = sess.run(outputs, feed_dict={X: x_train})\n",
        "    y_valid_pred = sess.run(outputs, feed_dict={X: x_valid})\n",
        "    y_test_pred = sess.run(outputs, feed_dict={X: x_test})\n",
        "    \n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:427: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be \"\n",
            "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "0.00 epochs: MSE train/valid = 0.252142/0.167522\n",
            "4.98 epochs: MSE train/valid = 0.000389/0.000787\n",
            "9.96 epochs: MSE train/valid = 0.000420/0.000651\n",
            "14.94 epochs: MSE train/valid = 0.000320/0.000534\n",
            "19.92 epochs: MSE train/valid = 0.000431/0.000564\n",
            "24.90 epochs: MSE train/valid = 0.000231/0.000451\n",
            "29.87 epochs: MSE train/valid = 0.000227/0.000430\n",
            "34.85 epochs: MSE train/valid = 0.000456/0.000539\n",
            "39.83 epochs: MSE train/valid = 0.000445/0.000530\n",
            "44.81 epochs: MSE train/valid = 0.000258/0.000434\n",
            "49.79 epochs: MSE train/valid = 0.000256/0.000426\n",
            "54.77 epochs: MSE train/valid = 0.000271/0.000430\n",
            "59.75 epochs: MSE train/valid = 0.000229/0.000444\n",
            "64.73 epochs: MSE train/valid = 0.000200/0.000426\n",
            "69.71 epochs: MSE train/valid = 0.000213/0.000434\n",
            "74.69 epochs: MSE train/valid = 0.000222/0.000419\n",
            "79.66 epochs: MSE train/valid = 0.000245/0.000457\n",
            "84.64 epochs: MSE train/valid = 0.000207/0.000428\n",
            "89.62 epochs: MSE train/valid = 0.000263/0.000449\n",
            "94.60 epochs: MSE train/valid = 0.000209/0.000435\n",
            "99.58 epochs: MSE train/valid = 0.000207/0.000423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_actual = scaler.inverse_transform(y_test)\n",
        "y_test_predictions = scaler.inverse_transform(y_test_pred)\n",
        "save = pd.DataFrame({'Open':y_test_actual[:,0],'High':y_test_actual[:,1], 'Low':y_test_actual[:,2],'Close':y_test_actual[:,3],'Open_Pred':y_test_predictions[:,0],'High_Pred':y_test_predictions[:,1], 'Low_Pred':y_test_predictions[:,2],'Close_Pred':y_test_predictions[:,3]})\n",
        "save.index= df.index[-y_test.shape[0]-1:-1]\n",
        "save.to_csv('../out/IBM_RNN_1234.csv')"
      ]
    }
  ]
}